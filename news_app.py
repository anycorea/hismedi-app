import json
import os
import re
import html
from datetime import date, timedelta

import pandas as pd
import streamlit as st
import gspread
from google.oauth2.service_account import Credentials


# =========================================================
# Config
# =========================================================
APP_TITLE = "ë‰´ìŠ¤ ëª¨ë‹ˆí„°"
DEFAULT_SHEET_ID = os.getenv("GSHEET_ID", "").strip()


# =========================================================
# Google Sheets (Service Account)
# =========================================================
def _normalize_private_key(info: dict) -> dict:
    """Normalize PEM so cryptography can parse it reliably."""
    info = dict(info)
    pk = info.get("private_key", "")
    if isinstance(pk, str) and pk:
        pk = pk.replace("\\n", "\n").replace("\r\n", "\n").replace("\r", "\n")
        lines = [ln.strip() for ln in pk.split("\n") if ln.strip() != ""]
        info["private_key"] = "\n".join(lines) + "\n"
    return info


@st.cache_resource
def get_gspread_client():
    # 1) Streamlit secrets ìš°ì„ 
    if "gcp_service_account" in st.secrets:
        info = _normalize_private_key(dict(st.secrets["gcp_service_account"]))
        creds = Credentials.from_service_account_info(
            info,
            scopes=["https://www.googleapis.com/auth/spreadsheets"],
        )
        return gspread.authorize(creds)

    # 2) env var fallback (JSON ë¬¸ìì—´)
    sa_json = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON", "").strip()
    if not sa_json:
        raise RuntimeError(
            "Missing [gcp_service_account] in secrets and GOOGLE_SERVICE_ACCOUNT_JSON env var."
        )
    info = json.loads(sa_json)
    info = _normalize_private_key(info)
    creds = Credentials.from_service_account_info(
        info,
        scopes=["https://www.googleapis.com/auth/spreadsheets"],
    )
    return gspread.authorize(creds)


@st.cache_data(ttl=120)
def load_news(sheet_id: str) -> pd.DataFrame:
    gc = get_gspread_client()
    sh = gc.open_by_key(sheet_id)
    ws_news = sh.get_worksheet(0)  # ì²« ì‹œíŠ¸(ì™¼ìª½)
    rows = ws_news.get_all_records()
    return pd.DataFrame(rows)


def _to_kst_datetime(series: pd.Series) -> pd.Series:
    """ISO8601(+09:00) ë¬¸ìì—´ì„ pandas datetimeìœ¼ë¡œ ë³€í™˜."""
    s = pd.to_datetime(series, errors="coerce", utc=False)
    if getattr(s.dt, "tz", None) is not None:
        s = s.dt.tz_convert("Asia/Seoul").dt.tz_localize(None)
    return s


def _clean_lead(title: str, text: str) -> str:
    """ìš”ì•½ì´ ì•ˆë‚´ë¬¸/ë©”íƒ€/ì œëª©ë°˜ë³µì¸ ê²½ìš°ë¥¼ ìµœëŒ€í•œ ì œê±°í•˜ê³ , 'ê¸°ì‚¬ ì²«ë¶€ë¶„'ì²˜ëŸ¼ ë³´ì´ê²Œ ì •ë¦¬."""
    t = (title or "").strip()
    s = (text or "").strip()
    if not s:
        return ""

    s = s.replace("\n", " ").replace("\r", " ")
    s = re.sub(r"\s+", " ", s).strip()

    # ë©”íƒ€/ì•ˆë‚´ ë¬¸êµ¬ ì œê±°(ë¹ˆë²ˆ íŒ¨í„´)
    boilerplate_patterns = [
        r"ì…ë ¥\s*\d{4}-\d{2}-\d{2}\s*\d{2}:\d{2}:\d{2}[^ ]*",
        r"ê¸°ì‚¬\s*ì½ì–´ì£¼ê¸°\s*ì„œë¹„ìŠ¤ëŠ”.*?ë¸Œë¼ìš°ì €ì—ì„œë§Œ\s*ì‚¬ìš©[^.ã€‚]*\.?$",
        r"ìµœê·¼\s*24ì‹œê°„\s*ì´ë‚´\s*ì†ë³´\s*ë°\s*ì•Œë¦¼ì„\s*í‘œì‹œí•©ë‹ˆë‹¤\.?$",
        r"â€»\s*ì´\s*ì‚¬ì§„ì€\s*ê¸°ì‚¬\s*ë‚´ìš©ê³¼\s*ê´€ë ¨ì´\s*ì—†ìŠµë‹ˆë‹¤\.?$",
        r"^\s*ì‚¬ì§„\s*=\s*[^ ]+\s*",
    ]
    for p in boilerplate_patterns:
        s = re.sub(p, " ", s, flags=re.IGNORECASE).strip()
        s = re.sub(r"\s+", " ", s).strip()

    # ì œëª© ë°˜ë³µ ì œê±°
    if t:
        if s.startswith(t):
            s = s[len(t):].lstrip(" -:Â·|ã€â€™'\"")
        if t in s:
            s = s.replace(t, " ").strip()
            s = re.sub(r"\s+", " ", s).strip()

    # ë¨¸ë¦¬í‘œ/ëŒ€ê´„í˜¸ ì ‘ë‘ ì œê±°
    s = re.sub(r"^(\[.*?\]\s*)+", "", s).strip()

    return s


# =========================================================
# UI
# =========================================================
st.set_page_config(page_title=APP_TITLE, layout="wide")

# --- Compact & modern spacing ---
st.markdown(
    """
    <style>
      .block-container { padding-top: 0.7rem !important; padding-bottom: 0.9rem !important; }
      .filter-box {
        border: 1px solid rgba(49, 51, 63, 0.14);
        border-radius: 16px;
        padding: 0.70rem 0.85rem;
        margin-bottom: 0.55rem;
        background: rgba(255, 255, 255, 0.02);
      }
      .filter-label {
        font-size: 0.85rem;
        font-weight: 650;
        color: rgba(49, 51, 63, 0.70);
        margin: 0 0 0.30rem 0;
      }
      div[data-testid="stButton"] > button { height: 42px; border-radius: 14px; padding: 0 14px; }
      div[data-baseweb="input"] input { height: 42px !important; }
      .news-wrap {
        border: 1px solid rgba(49, 51, 63, 0.14);
        border-radius: 16px;
        overflow: auto;
        max-height: 760px;
      }
      table.news {
        border-collapse: collapse;
        width: 100%;
        font-size: 14px;
      }
      table.news thead th {
        position: sticky;
        top: 0;
        background: rgba(250, 250, 250, 1);
        border-bottom: 1px solid rgba(49, 51, 63, 0.14);
        text-align: left;
        padding: 10px 12px;
        white-space: nowrap;
        z-index: 5;
      }
      table.news tbody td {
        border-bottom: 1px solid rgba(49, 51, 63, 0.08);
        padding: 10px 12px;
        vertical-align: top;
      }
      table.news tbody tr:hover td {
        background: rgba(49, 51, 63, 0.03);
      }
      .nowrap { white-space: nowrap; }
      a.newslink { text-decoration: none; }
      a.newslink:hover { text-decoration: underline; }
      .lead { color: rgba(49, 51, 63, 0.82); }
    </style>
    """,
    unsafe_allow_html=True,
)

sheet_id = st.secrets.get("GSHEET_ID", "").strip() or DEFAULT_SHEET_ID
if not sheet_id:
    st.error("GSHEET_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”.")
    st.stop()

# ---------------- Top filter row (ë™ê¸°í™” í¬í•¨) ----------------
st.markdown('<div class="filter-box">', unsafe_allow_html=True)

c0, c1, c2, c3 = st.columns([0.75, 1.15, 1.15, 2.2], vertical_alignment="center")

with c0:
    st.markdown('<div class="filter-label">&nbsp;</div>', unsafe_allow_html=True)
    if st.button("ğŸ”„ ë™ê¸°í™”", use_container_width=True):
        load_news.clear()

with c1:
    st.markdown('<div class="filter-label">ì‹œì‘ì¼</div>', unsafe_allow_html=True)
    default_from = date.today() - timedelta(days=7)
    date_from = st.date_input("ì‹œì‘ì¼", value=default_from, label_visibility="collapsed")

with c2:
    st.markdown('<div class="filter-label">ì¢…ë£Œì¼</div>', unsafe_allow_html=True)
    date_to = st.date_input("ì¢…ë£Œì¼", value=date.today(), label_visibility="collapsed")

with c3:
    st.markdown('<div class="filter-label">ê²€ìƒ‰(ì œëª©/ìš”ì•½)</div>', unsafe_allow_html=True)
    q = st.text_input("ê²€ìƒ‰(ì œëª©/ìš”ì•½)", value="", label_visibility="collapsed").strip()

st.markdown("</div>", unsafe_allow_html=True)

# ---------------- Load & normalize data ----------------
df = load_news(sheet_id)
if df.empty:
    st.warning("ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

df.columns = [str(c).strip() for c in df.columns]

published_col = None
for cand in ["published_at", "publishedAt", "pubDate", "date", "ë°œí–‰", "ë°œí–‰ì¼"]:
    if cand in df.columns:
        published_col = cand
        break
if published_col is None:
    st.error("ë°œí–‰ì¼ ì»¬ëŸ¼(published_at)ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

df["ë°œí–‰(KST)"] = _to_kst_datetime(df[published_col])

url_col = "url_canonical" if "url_canonical" in df.columns else ("url" if "url" in df.columns else None)
title_col = "title" if "title" in df.columns else None
summary_col = "summary" if "summary" in df.columns else None

if url_col is None or title_col is None:
    st.error("í•„ìˆ˜ ì»¬ëŸ¼(title, url/url_canonical)ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

df = df.sort_values("ë°œí–‰(KST)", ascending=False, na_position="last").reset_index(drop=True)

# ---------------- Apply filters ----------------
df_view = df[pd.notna(df["ë°œí–‰(KST)"])].copy()
df_view = df_view[df_view["ë°œí–‰(KST)"].dt.date >= date_from]
df_view = df_view[df_view["ë°œí–‰(KST)"].dt.date <= date_to]

if q:
    hay = df_view[title_col].fillna("").astype(str)
    if summary_col:
        hay = hay + " " + df_view[summary_col].fillna("").astype(str)
    df_view = df_view[hay.str.contains(q, case=False, na=False)]

if df_view.empty:
    st.info("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# ---------------- Build 'lead' preview (ê¸°ì‚¬ ì‹œì‘ë¶€ë¶„) ----------------
titles = df_view[title_col].fillna("").astype(str).tolist()
summaries = df_view[summary_col].fillna("").astype(str).tolist() if summary_col else [""] * len(df_view)

leads = []
for t, s in zip(titles, summaries):
    lead = _clean_lead(t, s)
    lead = lead[:180].rstrip()
    leads.append(lead)

# ---------------- Render table (ì œëª© í´ë¦­ = ì›ë¬¸) ----------------
rows_html = []
for idx, r in df_view.iterrows():
    pub = r.get("ë°œí–‰(KST)")
    pub_str = ""
    try:
        pub_ts = pd.to_datetime(pub, errors="coerce")
        if pd.notna(pub_ts):
            pub_str = pub_ts.strftime("%Y-%m-%d %H:%M")
    except Exception:
        pub_str = ""

    src = str(r.get("source", "")).strip()
    title = str(r.get(title_col, "")).strip()
    url = str(r.get(url_col, "")).strip()
    lead = leads[df_view.index.get_loc(idx)] if len(leads) == len(df_view) else ""

    pub_html = html.escape(pub_str)
    src_html = html.escape(src)
    title_html = html.escape(title)
    url_html = html.escape(url, quote=True)
    lead_html = html.escape(lead)

    rows_html.append(
        f"""<tr>
  <td class='nowrap'>{pub_html}</td>
  <td class='nowrap'>{src_html}</td>
  <td><a class='newslink' href='{url_html}' target='_blank' rel='noopener noreferrer'>{title_html}</a></td>
  <td class='lead'>{lead_html}</td>
</tr>"""
    )

table_html = f"""
<div class='news-wrap'>
  <table class='news'>
    <thead>
      <tr>
        <th class='nowrap'>ë°œí–‰</th>
        <th class='nowrap'>ì¶œì²˜</th>
        <th>ì œëª©</th>
        <th>ê¸°ì‚¬ ì‹œì‘ë¶€ë¶„</th>
      </tr>
    </thead>
    <tbody>
      {''.join(rows_html)}
    </tbody>
  </table>
</div>
"""

st.markdown(table_html, unsafe_allow_html=True)
