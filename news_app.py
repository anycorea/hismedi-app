import json
import os
from datetime import date, timedelta

import pandas as pd
import streamlit as st
import gspread
from google.oauth2.service_account import Credentials


# =========================================================
# Config
# =========================================================
APP_TITLE = "ë‰´ìŠ¤ ëª¨ë‹ˆí„°"  # ë¸Œë¼ìš°ì € íƒ­ ì œëª©(ë³¸ë¬¸ ì œëª©ì€ í‘œì‹œ ì•ˆ í•¨)
DEFAULT_SHEET_ID = os.getenv("GSHEET_ID", "").strip()


# =========================================================
# Google Sheets (Service Account)
# =========================================================
def _normalize_private_key(info: dict) -> dict:
    """Normalize PEM so cryptography can parse it reliably."""
    info = dict(info)
    pk = info.get("private_key", "")
    if isinstance(pk, str) and pk:
        pk = pk.replace("\\n", "\n").replace("\r\n", "\n").replace("\r", "\n")
        # strip per line to remove accidental leading/trailing spaces
        lines = [ln.strip() for ln in pk.split("\n") if ln.strip() != ""]
        info["private_key"] = "\n".join(lines) + "\n"
    return info


@st.cache_resource
def get_gspread_client():
    # 1) Streamlit secrets ìš°ì„ 
    if "gcp_service_account" in st.secrets:
        info = _normalize_private_key(dict(st.secrets["gcp_service_account"]))
        creds = Credentials.from_service_account_info(
            info,
            scopes=["https://www.googleapis.com/auth/spreadsheets"],
        )
        return gspread.authorize(creds)

    # 2) env var fallback (JSON ë¬¸ìžì—´)
    sa_json = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON", "").strip()
    if not sa_json:
        raise RuntimeError("Missing [gcp_service_account] in secrets and GOOGLE_SERVICE_ACCOUNT_JSON env var.")
    info = json.loads(sa_json)
    info = _normalize_private_key(info)
    creds = Credentials.from_service_account_info(
        info,
        scopes=["https://www.googleapis.com/auth/spreadsheets"],
    )
    return gspread.authorize(creds)


@st.cache_data(ttl=120)
def load_news_and_meta(sheet_id: str):
    gc = get_gspread_client()
    sh = gc.open_by_key(sheet_id)

    # News worksheet: ì²« ì‹œíŠ¸(ì™¼ìª½) ìš°ì„ 
    ws_news = sh.get_worksheet(0)
    rows = ws_news.get_all_records()
    df = pd.DataFrame(rows)

    # Meta worksheet: "meta" ì‹œíŠ¸ê°€ ìžˆìœ¼ë©´ ì½ê¸°(ì—†ìœ¼ë©´ ë¹ˆ dict)
    meta = {}
    try:
        ws_meta = sh.worksheet("meta")
        meta_rows = ws_meta.get_all_records()
        if meta_rows:
            meta_df = pd.DataFrame(meta_rows)
            if {"key", "value"}.issubset(meta_df.columns):
                meta = dict(zip(meta_df["key"].astype(str), meta_df["value"].astype(str)))
    except Exception:
        pass

    return df, meta


def _to_kst_datetime(series: pd.Series) -> pd.Series:
    """
    published_at ê°™ì€ ISO8601(+09:00) ë¬¸ìžì—´ì„ pandas datetimeìœ¼ë¡œ.
    tz-awareë¡œ íŒŒì‹±ëœ ê²½ìš° KSTë¡œ ë³€í™˜ í›„ tz ì •ë³´ ì œê±°(í‘œì‹œ/í•„í„° íŽ¸ì˜).
    """
    s = pd.to_datetime(series, errors="coerce", utc=False)
    # tz-awareë©´ KSTë¡œ ë³€í™˜ â†’ naiveë¡œ
    if getattr(s.dt, "tz", None) is not None:
        s = s.dt.tz_convert("Asia/Seoul").dt.tz_localize(None)
    return s


# =========================================================
# UI
# =========================================================
st.set_page_config(page_title=APP_TITLE, layout="wide")

# íƒ€ì´í‹€(ë³¸ë¬¸) ì œê±°: í•„ìš” ìµœì†Œ UIë§Œ
# st.title(...) ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

# Sheet ID ê²°ì •: secrets > env > ìƒìˆ˜
sheet_id = (
    st.secrets.get("GSHEET_ID", "").strip()
    or DEFAULT_SHEET_ID
)

if not sheet_id:
    st.error("GSHEET_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”.")
    st.stop()

# ìƒë‹¨ ì»¨íŠ¸ë¡¤(ëª¨ë°”ì¼ì—ì„œë„ ë³¸ë¬¸ì— ê·¸ëŒ€ë¡œ ë³´ì´ë„ë¡ sidebar ë¯¸ì‚¬ìš©)
top_left, top_right = st.columns([1, 2], vertical_alignment="center")
with top_left:
    if st.button("ðŸ”„ ìƒˆë¡œê³ ì¹¨(ì‹œíŠ¸ ë‹¤ì‹œ ì½ê¸°)"):
        load_news_and_meta.clear()

with top_right:
    st.caption("í•„í„°ëŠ” ì•„ëž˜ì—ì„œ ì¡°ì ˆí•  ìˆ˜ ìžˆì–´ìš”. (ëª¨ë°”ì¼ì—ì„œë„ ë³¸ë¬¸ì— í‘œì‹œë©ë‹ˆë‹¤)")

df, meta = load_news_and_meta(sheet_id)

if df.empty:
    st.warning("ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# ì»¬ëŸ¼ í‘œì¤€í™”
# (ì‹œíŠ¸ë§ˆë‹¤ ëŒ€ì†Œë¬¸ìž/ê³µë°±ì´ ì„žì¼ ìˆ˜ ìžˆì–´ ë°©ì–´)
df.columns = [str(c).strip() for c in df.columns]

# published_at -> ë°œí–‰(KST)
published_col = "published_at" if "published_at" in df.columns else None
if not published_col:
    # í˜¹ì‹œ ë‹¤ë¥¸ ì´ë¦„ì´ë©´ í›„ë³´ íƒìƒ‰
    for cand in ["ë°œí–‰", "ë°œí–‰ì¼", "publishedAt", "pubDate", "date"]:
        if cand in df.columns:
            published_col = cand
            break

if published_col is None:
    st.error("ë°œí–‰ì¼ ì»¬ëŸ¼(published_at)ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

df["ë°œí–‰(KST)"] = _to_kst_datetime(df[published_col])

# ì •ë ¬
df = df.sort_values("ë°œí–‰(KST)", ascending=False, na_position="last").reset_index(drop=True)

# ---------------- Filters (ë³¸ë¬¸ì— ë°°ì¹˜) ----------------
with st.expander("í•„í„°", expanded=True):
    f1, f2, f3 = st.columns([1, 1, 2])
    with f1:
        default_from = date.today() - timedelta(days=7)
        date_from = st.date_input("ì‹œìž‘ì¼", value=default_from)
    with f2:
        date_to = st.date_input("ì¢…ë£Œì¼", value=date.today())
    with f3:
        q = st.text_input("ê²€ìƒ‰(ì œëª©/ìš”ì•½)", value="").strip()

    # íƒœê·¸ í•„í„°(ìžˆìœ¼ë©´)
    tag = None
    if "tags" in df.columns:
        tags = sorted({t.strip() for t in df["tags"].dropna().astype(str).tolist() if t.strip()})
        if tags:
            tag = st.selectbox("íƒœê·¸", options=["(ì „ì²´)"] + tags, index=0)

# í•„í„° ì ìš©
df_view = df.copy()

if pd.notna(df_view["ë°œí–‰(KST)"]).any():
    df_view = df_view[df_view["ë°œí–‰(KST)"].dt.date >= date_from]
    df_view = df_view[df_view["ë°œí–‰(KST)"].dt.date <= date_to]

if q:
    hay = ""
    if "title" in df_view.columns:
        hay = df_view["title"].fillna("").astype(str)
    if "summary" in df_view.columns:
        hay = hay + " " + df_view["summary"].fillna("").astype(str)
    df_view = df_view[hay.str.contains(q, case=False, na=False)]

if tag and tag != "(ì „ì²´)" and "tags" in df_view.columns:
    df_view = df_view[df_view["tags"].fillna("").astype(str).str.contains(tag, na=False)]

# ---------------- Result ----------------
st.subheader("ê¸°ì‚¬ ëª©ë¡")

if df_view.empty:
    st.info("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹œìž‘ì¼/ì¢…ë£Œì¼ ë˜ëŠ” ê²€ìƒ‰ì–´ë¥¼ ì¡°ì •í•´ ë³´ì„¸ìš”.")
    st.stop()

# ë§í¬: url_canonical ìš°ì„ , ì—†ìœ¼ë©´ url
url_col = "url_canonical" if "url_canonical" in df_view.columns else ("url" if "url" in df_view.columns else None)
title_col = "title" if "title" in df_view.columns else None

# ëª¨ë°”ì¼/í´ë¦­ UX ìµœìš°ì„ : DataFrame ëŒ€ì‹  'ë¦¬ìŠ¤íŠ¸ ì¹´ë“œ' í˜•íƒœë¡œ ì¶œë ¥ (í´ë¦­í•˜ë©´ ë°”ë¡œ ì›ë¬¸ ì—´ë¦¼)
for _, r in df_view.iterrows():
    t = str(r.get(title_col, "")).strip() if title_col else ""
    u = str(r.get(url_col, "")).strip() if url_col else ""
    src = str(r.get("source", "")).strip()
    tags = str(r.get("tags", "")).strip()
    summ = str(r.get("summary", "")).strip() if "summary" in df_view.columns else ""

    if not t and not u:
        continue

    # ì œëª© í´ë¦­ â†’ ì›ë¬¸ ì—´ê¸° (ìƒˆ íƒ­)
    if t and u:
        st.markdown(f"**[{t}]({u})**")
    elif u:
        st.markdown(f"**[ì›ë¬¸ ì—´ê¸°]({u})**")
    else:
        st.markdown(f"**{t}**")

        pub = r.get("ë°œí–‰(KST)")
    pub_str = ""
    try:
        if pd.notna(pub):
            # pub can be pandas Timestamp/datetime
            pub_str = pd.to_datetime(pub, errors="coerce")
            if pd.notna(pub_str):
                pub_str = pub_str.strftime("%Y-%m-%d %H:%M")
            else:
                pub_str = ""
        else:
            pub_str = ""
    except Exception:
        pub_str = ""

    meta_parts = [p for p in [pub_str, (src if src else ""), (tags if tags else "")] if str(p).strip() != ""]
    meta_line = " Â· ".join(meta_parts)

    if meta_line:
        st.caption(meta_line)

    if summ:
        st.write(summ)

    st.divider()

# ---------------- ìš´ì˜ ì•ˆë‚´ ----------------
with st.expander("ìš´ì˜ ì•ˆë‚´", expanded=False):
    st.write("GitHub Actions ë˜ëŠ” ë³„ë„ ìˆ˜ì§‘ ìž‘ì—…ì´ ì‹œíŠ¸ë¥¼ ê°±ì‹ í•˜ë©´ ìžë™ìœ¼ë¡œ ë°˜ì˜ë©ë‹ˆë‹¤.")
    if meta:
        st.caption("ë©”íƒ€ ì •ë³´")
        st.json(meta)
