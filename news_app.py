import json
import os
import re
from datetime import date, timedelta

import pandas as pd
import streamlit as st
import gspread
from google.oauth2.service_account import Credentials


# =========================================================
# Config
# =========================================================
APP_TITLE = "ë‰´ìŠ¤ ëª¨ë‹ˆí„°"
DEFAULT_SHEET_ID = os.getenv("GSHEET_ID", "").strip()


# =========================================================
# Google Sheets (Service Account)
# =========================================================
def _normalize_private_key(info: dict) -> dict:
    """Normalize PEM so cryptography can parse it reliably."""
    info = dict(info)
    pk = info.get("private_key", "")
    if isinstance(pk, str) and pk:
        pk = pk.replace("\\n", "\n").replace("\r\n", "\n").replace("\r", "\n")
        lines = [ln.strip() for ln in pk.split("\n") if ln.strip() != ""]
        info["private_key"] = "\n".join(lines) + "\n"
    return info


@st.cache_resource
def get_gspread_client():
    # 1) Streamlit secrets ìš°ì„ 
    if "gcp_service_account" in st.secrets:
        info = _normalize_private_key(dict(st.secrets["gcp_service_account"]))
        creds = Credentials.from_service_account_info(
            info,
            scopes=["https://www.googleapis.com/auth/spreadsheets"],
        )
        return gspread.authorize(creds)

    # 2) env var fallback (JSON ë¬¸ìì—´)
    sa_json = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON", "").strip()
    if not sa_json:
        raise RuntimeError(
            "Missing [gcp_service_account] in secrets and GOOGLE_SERVICE_ACCOUNT_JSON env var."
        )
    info = json.loads(sa_json)
    info = _normalize_private_key(info)
    creds = Credentials.from_service_account_info(
        info,
        scopes=["https://www.googleapis.com/auth/spreadsheets"],
    )
    return gspread.authorize(creds)


@st.cache_data(ttl=120)
def load_news(sheet_id: str) -> pd.DataFrame:
    gc = get_gspread_client()
    sh = gc.open_by_key(sheet_id)
    ws_news = sh.get_worksheet(0)  # ì²« ì‹œíŠ¸(ì™¼ìª½)
    rows = ws_news.get_all_records()
    return pd.DataFrame(rows)


def _to_kst_datetime(series: pd.Series) -> pd.Series:
    """ISO8601(+09:00) ë¬¸ìì—´ì„ pandas datetimeìœ¼ë¡œ ë³€í™˜."""
    s = pd.to_datetime(series, errors="coerce", utc=False)
    if getattr(s.dt, "tz", None) is not None:
        s = s.dt.tz_convert("Asia/Seoul").dt.tz_localize(None)
    return s


def _clean_summary(title: str, summary: str) -> str:
    """
    'ìš”ì•½' ì»¬ëŸ¼ì´ ì‹¤ì œ ìš”ì•½ì´ ì•„ë‹ˆë¼,
    - ì œëª© ë°˜ë³µ
    - 'ê¸°ì‚¬ ì½ì–´ì£¼ê¸° ì„œë¹„ìŠ¤...', 'ìµœê·¼ 24ì‹œê°„...' ê°™ì€ ê³ ì • ì•ˆë‚´ë¬¸
    - 'ì…ë ¥ 2025-...' ê°™ì€ ë©”íƒ€ ë¬¸êµ¬
    ë¡œ ì±„ì›Œì§€ëŠ” ê²½ìš°ê°€ ë§ì•„ í™”ë©´ì—ì„œ ì œê±°/ì •ë¦¬í•©ë‹ˆë‹¤.

    ì „ëµ:
    1) ê³ ì • ì•ˆë‚´/ë©”íƒ€ ë¬¸êµ¬ ì œê±°
    2) ì œëª© ë°˜ë³µ ì œê±°
    3) ì •ë¦¬ í›„ ë„ˆë¬´ ì§§ê±°ë‚˜ ì•ˆë‚´ë¬¸ ì„±ê²©ì´ë©´ ë¹ˆì¹¸ ì²˜ë¦¬
    """
    t = (title or "").strip()
    s = (summary or "").strip()
    if not s:
        return ""

    # normalize whitespace
    s = s.replace("\n", " ").replace("\r", " ")
    s = re.sub(r"\s+", " ", s).strip()

    # remove common boilerplate phrases (Korean news feeds)
    boilerplate_patterns = [
        r"ì…ë ¥\s*\d{4}-\d{2}-\d{2}\s*\d{2}:\d{2}:\d{2}[^ ]*",
        r"ê¸°ì‚¬\s*ì½ì–´ì£¼ê¸°\s*ì„œë¹„ìŠ¤ëŠ”.*?ë¸Œë¼ìš°ì €ì—ì„œë§Œ\s*ì‚¬ìš©[^.ã€‚]*\.?$",
        r"ìµœê·¼\s*24ì‹œê°„\s*ì´ë‚´\s*ì†ë³´\s*ë°\s*ì•Œë¦¼ì„\s*í‘œì‹œí•©ë‹ˆë‹¤\.?$",
        r"â€»\s*ì´\s*ì‚¬ì§„ì€\s*ê¸°ì‚¬\s*ë‚´ìš©ê³¼\s*ê´€ë ¨ì´\s*ì—†ìŠµë‹ˆë‹¤\.?$",
        r"^\s*ì‚¬ì§„\s*=\s*[^ ]+\s*",
    ]
    for p in boilerplate_patterns:
        s = re.sub(p, " ", s, flags=re.IGNORECASE).strip()
        s = re.sub(r"\s+", " ", s).strip()

    # remove title repetitions
    if t:
        if s.startswith(t):
            s = s[len(t):].lstrip(" -:Â·|ã€â€™'\"")
        if t in s:
            s = s.replace(t, " ").strip()
            s = re.sub(r"\s+", " ", s).strip()

    # remove bracketed prefixes like [ë‹¨ë…], [ë¦¬í¬íŠ¸]
    s = re.sub(r"^(\[.*?\]\s*)+", "", s).strip()

    # If summary still looks like a notice, drop it
    if re.search(r"(ì½ì–´ì£¼ê¸°\s*ì„œë¹„ìŠ¤|ë¸Œë¼ìš°ì €ì—ì„œë§Œ\s*ì‚¬ìš©|ì†ë³´\s*ë°\s*ì•Œë¦¼)", s):
        return ""

    # too short => not a real summary
    if len(s) < 40:
        return ""

    return s


# =========================================================
# UI
# =========================================================
st.set_page_config(page_title=APP_TITLE, layout="wide")

# --- Compact spacing ---
st.markdown(
    """
    <style>
      .block-container { padding-top: 0.8rem !important; padding-bottom: 1.0rem !important; }
      .filter-box {
        border: 1px solid rgba(49, 51, 63, 0.16);
        border-radius: 14px;
        padding: 0.75rem 0.85rem;
        margin-bottom: 0.6rem;
        background: rgba(255, 255, 255, 0.02);
      }
      .filter-label {
        font-size: 0.85rem;
        font-weight: 600;
        color: rgba(49, 51, 63, 0.75);
        margin: 0 0 0.35rem 0;
      }
      div[data-testid="stButton"] > button { height: 42px; border-radius: 12px; padding: 0 14px; }
      div[data-baseweb="input"] input { height: 42px !important; }
    </style>
    """,
    unsafe_allow_html=True,
)

sheet_id = st.secrets.get("GSHEET_ID", "").strip() or DEFAULT_SHEET_ID
if not sheet_id:
    st.error("GSHEET_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”.")
    st.stop()

# ---------------- Top filter row (ë™ê¸°í™” í¬í•¨) ----------------
st.markdown('<div class="filter-box">', unsafe_allow_html=True)

c0, c1, c2, c3 = st.columns([0.75, 1.15, 1.15, 2.2], vertical_alignment="center")

with c0:
    st.markdown('<div class="filter-label">&nbsp;</div>', unsafe_allow_html=True)
    if st.button("ğŸ”„ ë™ê¸°í™”", use_container_width=True):
        load_news.clear()

with c1:
    st.markdown('<div class="filter-label">ì‹œì‘ì¼</div>', unsafe_allow_html=True)
    default_from = date.today() - timedelta(days=7)
    date_from = st.date_input("ì‹œì‘ì¼", value=default_from, label_visibility="collapsed")

with c2:
    st.markdown('<div class="filter-label">ì¢…ë£Œì¼</div>', unsafe_allow_html=True)
    date_to = st.date_input("ì¢…ë£Œì¼", value=date.today(), label_visibility="collapsed")

with c3:
    st.markdown('<div class="filter-label">ê²€ìƒ‰(ì œëª©/ìš”ì•½)</div>', unsafe_allow_html=True)
    q = st.text_input("ê²€ìƒ‰(ì œëª©/ìš”ì•½)", value="", label_visibility="collapsed").strip()

st.markdown("</div>", unsafe_allow_html=True)

# ---------------- Load & normalize data ----------------
df = load_news(sheet_id)
if df.empty:
    st.warning("ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

df.columns = [str(c).strip() for c in df.columns]

published_col = None
for cand in ["published_at", "publishedAt", "pubDate", "date", "ë°œí–‰", "ë°œí–‰ì¼"]:
    if cand in df.columns:
        published_col = cand
        break

if published_col is None:
    st.error("ë°œí–‰ì¼ ì»¬ëŸ¼(published_at)ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

df["ë°œí–‰(KST)"] = _to_kst_datetime(df[published_col])

url_col = "url_canonical" if "url_canonical" in df.columns else ("url" if "url" in df.columns else None)
title_col = "title" if "title" in df.columns else None

df = df.sort_values("ë°œí–‰(KST)", ascending=False, na_position="last").reset_index(drop=True)

# ---------------- Apply filters ----------------
df_view = df[pd.notna(df["ë°œí–‰(KST)"])].copy()
df_view = df_view[df_view["ë°œí–‰(KST)"].dt.date >= date_from]
df_view = df_view[df_view["ë°œí–‰(KST)"].dt.date <= date_to]

if q:
    hay = ""
    if title_col:
        hay = df_view[title_col].fillna("").astype(str)
    if "summary" in df_view.columns:
        hay = hay + " " + df_view["summary"].fillna("").astype(str)
    df_view = df_view[hay.str.contains(q, case=False, na=False)]

if df_view.empty:
    st.info("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# ---------------- Table view ----------------
show_cols = ["ë°œí–‰(KST)"]
if "source" in df_view.columns:
    show_cols.append("source")
if title_col:
    show_cols.append(title_col)
if "summary" in df_view.columns:
    show_cols.append("summary")
if url_col:
    show_cols.append(url_col)

df_out = df_view[show_cols].copy()

rename_map = {"ë°œí–‰(KST)": "ë°œí–‰", "source": "ì¶œì²˜"}
if title_col:
    rename_map[title_col] = "ì œëª©"
if "summary" in df_out.columns:
    rename_map["summary"] = "ìš”ì•½"
if url_col:
    rename_map[url_col] = "ì›ë¬¸"

df_out = df_out.rename(columns=rename_map)

df_out["ë°œí–‰"] = pd.to_datetime(df_out["ë°œí–‰"], errors="coerce").dt.strftime("%Y-%m-%d %H:%M")

if "ìš”ì•½" in df_out.columns:
    if "ì œëª©" in df_out.columns:
        df_out["ìš”ì•½"] = [
            _clean_summary(t, s)
            for t, s in zip(
                df_out["ì œëª©"].fillna("").astype(str),
                df_out["ìš”ì•½"].fillna("").astype(str),
            )
        ]
    else:
        df_out["ìš”ì•½"] = df_out["ìš”ì•½"].fillna("").astype(str)

    df_out["ìš”ì•½"] = (
        pd.Series(df_out["ìš”ì•½"])
        .fillna("")
        .astype(str)
        .str.replace("\n", " ", regex=False)
        .str.replace("\r", " ", regex=False)
        .str.replace("  ", " ", regex=False)
        .str.strip()
        .str.slice(0, 220)
    )

column_config = {}
if "ì›ë¬¸" in df_out.columns:
    try:
        column_config["ì›ë¬¸"] = st.column_config.LinkColumn("ì›ë¬¸")
    except Exception:
        pass

st.dataframe(
    df_out,
    use_container_width=True,
    height=760,
    hide_index=True,
    column_config=column_config if column_config else None,
)
